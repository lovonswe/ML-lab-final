{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s7WqtMK08a1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "url = \"/content/drive/MyDrive/Dataset/bank-data/bank-data/bank-full.csv\"\n",
        "bank_data = pd.read_csv(url, delimiter=';')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adHm6JR91PJk",
        "outputId": "ca0fffbd-3b73-4017-9e50-6f70c46252a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minbit = 1\n",
        "maxbit = 255\n",
        "RESCALE = minbit/maxbit\n",
        "SHEAR = 0.3\n",
        "ZOOM = 0.3\n",
        "FLIP = True\n",
        "batch = 32\n",
        "imgageHeight = 200\n",
        "imageWidth = 200\n",
        "augmented_train_data = ImageDataGenerator(horizontal_flip=FLIP)\n",
        "augmented_val_data = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "RGDFB4mL1WqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate batches of augmented data\n",
        "train = augmented_train_data.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Dataset/Archive/train',(200, 200), 32\n",
        ")\n",
        "\n",
        "val = augmented_val_data.flow_from_directory(\n",
        "   '/content/drive/MyDrive/Dataset/Archive/val',(200, 200), 32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LL2YVSy1v3u",
        "outputId": "0456895b-6437-4faa-902a-538bb3aaf6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the model..\n",
        "from tensorflow.keras import models, layers\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))  # Adding dropout for regularization\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "iRcZVidl1yHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model tranning phase\n",
        "history = model.fit( train, len(train), val, len(val) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVfPRZKC14Mx",
        "outputId": "240a8c03-1a2b-41e0-d128-172193847fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "163/163 [==============================] - 1094s 6s/step - loss: 0.3447 - accuracy: 0.8461 - val_loss: 0.8272 - val_accuracy: 0.7500\n",
            "Epoch 2/10\n",
            "163/163 [==============================] - 364s 2s/step - loss: 0.2337 - accuracy: 0.9112 - val_loss: 1.0077 - val_accuracy: 0.6250\n",
            "Epoch 3/10\n",
            "163/163 [==============================] - 359s 2s/step - loss: 0.1911 - accuracy: 0.9241 - val_loss: 0.9403 - val_accuracy: 0.6250\n",
            "Epoch 4/10\n",
            "163/163 [==============================] - 366s 2s/step - loss: 0.1725 - accuracy: 0.9300 - val_loss: 0.4626 - val_accuracy: 0.8125\n",
            "Epoch 5/10\n",
            "163/163 [==============================] - 365s 2s/step - loss: 0.1509 - accuracy: 0.9442 - val_loss: 0.4435 - val_accuracy: 0.7500\n",
            "Epoch 6/10\n",
            "163/163 [==============================] - 349s 2s/step - loss: 0.1435 - accuracy: 0.9459 - val_loss: 1.5008 - val_accuracy: 0.5625\n",
            "Epoch 7/10\n",
            "163/163 [==============================] - 354s 2s/step - loss: 0.1401 - accuracy: 0.9486 - val_loss: 0.5745 - val_accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "163/163 [==============================] - 339s 2s/step - loss: 0.1308 - accuracy: 0.9479 - val_loss: 1.3179 - val_accuracy: 0.5625\n",
            "Epoch 9/10\n",
            "163/163 [==============================] - 348s 2s/step - loss: 0.1340 - accuracy: 0.9471 - val_loss: 1.2396 - val_accuracy: 0.6250\n",
            "Epoch 10/10\n",
            "163/163 [==============================] - 343s 2s/step - loss: 0.1180 - accuracy: 0.9548 - val_loss: 0.2159 - val_accuracy: 0.8750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Dataset/Archive/test', (200, 200), 32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDLrwMT-18F_",
        "outputId": "f5f84396-3aa3-46a3-b019-b83697997f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation with test data\n",
        "test_loss, test_acc = model.evaluate(test_generator, steps=len(test_generator))\n",
        "\n",
        "#print accuracy of the model on test data\n",
        "print(\"test data accuracy: {:.2f}%\".format(test_acc * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wByU5UVx19TR",
        "outputId": "f0cc08f5-e040-4a63-d490-b6f087b94e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 135s 7s/step - loss: 0.2447 - accuracy: 0.9247\n",
            "test data accuracy: 92.47%\n"
          ]
        }
      ]
    }
  ]
}